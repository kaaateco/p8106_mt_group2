---
title: "P8106 Midterm - Code"
author: "Kate Colvin (KAC2301), Jeong Yun (Lizy) Choi (JC6452), and Flora Pang (FP2513)"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gtsummary)
library(gt)
library(corrplot)
library(kableExtra)

library(caret)
library(glmnet) 
library(earth) 
library(mlbench)
library(pROC)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(ISLR)
library(pls)
library(tidymodels)
library(mgcv)
library(pdp)

```

# Exploratory Analysis 

### Loading in Data

```{r}

load("dat1.RData") 
load("dat2.RData")

dat1 <- dat1 %>% janitor::clean_names()
dat2 <- dat2 %>%janitor::clean_names()

```

### Producing Summary Table

Training and test data have the same distribution of demographic characteristics; there is a difference in time since vaccination and log-transformed antibody levels between training and test data

```{r}

# Combining data for summary table, data cleaning
dat1_com <- dat1 %>% mutate(set = "Training Data")
dat2_com <- dat2 %>% mutate(set = "Testing Data")

dat <- dat1_com %>% 
  rbind(dat2_com) %>% 
  rename(days_vaccinated = time) %>% 
  mutate(race = as.character(race), smoking = as.character(smoking)) %>% 
  mutate(race = case_match(
        race, "1" ~ "White", "2" ~ "Asian", "3" ~ "Black", "4" ~ "Hispanic"),
         gender = case_match(gender, 1 ~ "Male", 0 ~ "Female"), 
         smoking = case_match(
           smoking, "0" ~ "Never", "1" ~ "Former", "2" ~ "Current"))

# Summary table
dat %>% select(!id) %>% 
  tbl_summary(
    by = set, 
    label = list(age = "Age", gender = "Gender", race = "Race", smoking = "Smoking", 
                 height = "Height (cm)", weight = "Weight (kg)", bmi = "BMI", 
                 diabetes = "Diabetes", hypertension = "Hypertension", 
                 sbp = "Systolic Blood Pressure (mmHg)", ldl = "LDL Cholesterol (mg/dL)", 
                 days_vaccinated = "Time Since Vaccinated (days)", 
                 log_antibody = "Log-Transformed Antibody Level")) %>% 
  add_overall() %>% add_p() %>% 
  modify_caption("Summary of Patient Testing and Training Data (N=6000)") %>% 
  as_gt() %>% tab_options(table.font.size = 10)

```


### Histograms of Differing Variables by Training and Test Set

```{r, out.width = "95%", fig.align = "center"}

# Antibody level 
plot_sets <- dat %>%  
  ggplot(aes(x = log_antibody, 
             fill = set, 
             color = set)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Log-Transformed Antibody Level", 
       y = "Density", 
       title = "Figure 1: Distribution of Log-Transformed Antibody Level, by Data Set") +
  theme_minimal()

# Time since vaccination (days)
plot_days <- dat %>%  
  ggplot(aes(x = days_vaccinated, 
             fill = set, 
             color = set)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Time Since Vaccinated (days)", 
       y = "Density", 
       title = "Figure 2: Distribution of Days Since Vaccination, by Data Set") +
  theme_minimal()

plot_sets
plot_days

```


### Plots of Log-Transformed Antibody Level, by Categorical Variables

```{r, out.width = "100%", fig.align = "center"}
# Antibody level, by gender
plot_gender <- dat %>%  
  ggplot(aes(x = log_antibody, fill = gender, color = gender)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Log-Transformed Antibody Level", y = "Density", 
       title = "Figure 3: Distribution of Log-Transformed Antibody Level, by Gender") +
  theme_minimal()
plot_gender

strip_markdown <- function(x) {gsub("\\*\\*", "", x)}

dat %>% select(gender, log_antibody) %>% 
  tbl_summary(by = gender) %>% add_p() %>% 
  modify_caption("Log-Transformed Antibody Level, by Gender") %>% 
  as_kable() %>% 
  footnote(general_title = "", general = "Median (Q1, Q3), Wilcoxon Rank Sum Test") %>% 
  strip_markdown()

```



```{r}
# Antibody level, by race
plot_race <- dat %>%  
  ggplot(aes(x = log_antibody, fill = race, color = race)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Log-Transformed Antibody Level", 
       y = "Density", 
       title = "Figure 4: Distribution of Log-Transformed Antibody Level, by Race") +
  theme_minimal()

plot_race

dat %>% 
  select(race, log_antibody) %>% 
  tbl_summary(by = race) %>% 
    add_p() %>% 
  modify_caption("Log-Transformed Antibody Level, by Race") %>% 
  as_kable() %>% 
  footnote(general_title = "", 
           general = "Median (Q1, Q3), Kruskal-Wallis Rank Sum Test") %>% 
  strip_markdown()

```

```{r}
# Antibody level, by smoking status 
plot_smoking <- dat %>%  
  ggplot(aes(x = log_antibody, fill = smoking, color = smoking)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Log-Transformed Antibody Level", 
       y = "Density", 
       title = "Figure 5: Distribution of Log-Transformed Antibody Level, by Smoking") +
  theme_minimal()
plot_smoking

dat %>% select(smoking, log_antibody) %>% 
  tbl_summary(by = smoking) %>% 
    add_p() %>% 
  modify_caption("Log-Transformed Antibody Level, by Smoking Status") %>% 
  as_kable() %>% 
  footnote(general_title = "", 
           general = "Median (Q1, Q3), Kruskal-Wallis Rank Sum Test") %>% 
  strip_markdown()

```


### Correlation Matrix of Numerical Variables 

```{r, warning=FALSE}

cor_matrix <- dat %>% 
  select(age, height, weight, bmi, sbp, ldl, days_vaccinated, log_antibody) %>% 
  rename("Age" = age, 
         "Height" = height,
         "Weight" = weight,
         "BMI" = bmi,
         "SBP" = sbp, 
         "LDL" = ldl,
         "Days Vaccinated" = days_vaccinated, 
         "Log(Antibody)" = log_antibody) %>% 
  cor()

cor_plot <- corrplot(cor_matrix,  
                     main = "Figure 6: Correlation Matrix of Numerical Variables", 
                     mar=c(0,0,1,0), cex.main = 1,
                     method = "color", 
                     addCoef.col = "black", 
                     tl.col = "black", 
                     number.cex = 0.8, 
                     tl.srt = 45, 
                     order = 'original', 
                     diag = F)

```

\newpage

### Plots of Log-Transformed Antibody Level vs. Selected Numerical Variables

```{r, message=FALSE, out.width="90%", fig.align = "center"}
# Antibody level vs. BMI
plot_bmi <- dat %>% ggplot(aes(x = bmi, y = log_antibody, fill = set, color = set)) +
  geom_point(alpha = 0.3, size = 2) +
  geom_smooth(method = "lm") +
  labs(y = "Log-Transformed Antibody Level", x = "BMI", 
       title = "Figure 7: Log-Transformed Antibody Level vs. BMI") +
  theme_minimal()

# Antibody level vs. Weight
plot_weight <- dat %>% 
  ggplot(aes(x = weight, y = log_antibody, fill = set, color = set)) +
  geom_point(alpha = 0.3, size = 2) +
  geom_smooth(method = "lm") +
  labs(y = "Log-Transformed Antibody Level", x = "Weight", 
       title = "Figure 8: Log-Transformed Antibody Level vs. Weight") +
  theme_minimal()

# Antibody level vs. Age
plot_age <- dat %>% ggplot(aes(x = age, y = log_antibody, fill = set, color = set)) +
  geom_point(alpha = 0.3, size = 2) + geom_smooth(method = "lm") +
  labs(y = "Log-Transformed Antibody Level", x = "Age", 
       title = "Figure 9: Log-Transformed Antibody Level vs. Age") +
  theme_minimal()

plot_bmi
plot_weight
plot_age

```


\newpage

# Model Selection and Training

Since the response variable (log_antibody) is continuous, this project will consider the following models:

* Multiple Linear Regression (MLR) - as a baseline.

* LASSO Regression – to improve predictive performance by selecting important predictors.

* MARS model – allow remain in regression but also capture nonlinear effects

After comparing model performance, the best model will be based on cross-validation results.

## Data Pre-processing

```{r}
# Converting categorical variables into factors
dat1 <- dat1 %>%
  mutate(
    gender = factor(gender, levels = c(0, 1), labels = c("Female", "Male")),
    race = factor(race, levels = c(1, 2, 3, 4), labels = c("White", "Asian", "Black", "Hispanic")),
    smoking = factor(smoking, levels = c(0, 1, 2), labels = c("Never", "Former", "Current")),
    diabetes = factor(diabetes),
    hypertension = factor(hypertension)
  )

dat2 <- dat2 %>%
  mutate(
    gender = factor(gender, levels = c(0, 1), labels = c("Female", "Male")),
    race = factor(race, levels = c(1, 2, 3, 4), labels = c("White", "Asian", "Black", "Hispanic")),
    smoking = factor(smoking, levels = c(0, 1, 2), labels = c("Never", "Former", "Current")),
    diabetes = factor(diabetes),
    hypertension = factor(hypertension)
  )

```

```{r}
sum(is.na(dat1))
sum(is.na(dat2))
```

```{r}
dat1 <- dat1 %>% select(-id)
dat2 <- dat2 %>% select(-id)
```

## Training multiple linear regression model 

```{r}
# train control
set.seed(123)
ctrl1 = trainControl(method = "cv", number = 10)
```

```{r}
mlr_model <- lm(log_antibody ~ ., data = dat1)
summary(mlr_model)
```

```{r}
##using caret to see the difference in model result
mlr_fit <- train(
  log_antibody ~ ., 
  data = dat1, 
  method = "lm",
  trControl = ctrl1
)

summary(mlr_fit)
```

```{r}
# Evaluating model performance on validation data
mlr_pred <- predict(mlr_model, newdata = dat2)
mlr_rmse <- sqrt(mean((mlr_pred - dat2$log_antibody)^2))
mlr_adj_r2 <- summary(mlr_model)$adj.r.squared
mlr_rmse
mlr_adj_r2
```

```{r}
mlr_caret_pred <- predict(mlr_fit, newdata = dat2)
mlr_caret_rmse <- sqrt(mean((mlr_caret_pred - dat2$log_antibody)^2))
mlr_adj_r2_caret <- summary(mlr_fit)$adj.r.squared
mlr_caret_rmse
mlr_adj_r2_caret
```

To confirm consistency, we also fit the final linear regression model using the caret package in addition to the standard lm() function. Both approaches produced identical results in terms of coefficients, RMSE, and adjusted R-squared, confirming that the modeling framework did not influence the outcome. This consistency supports the reliability of our findings regardless of the implementation method.

## Training LASSO regression model

### Standardizing numerical variables for LASSO using glmnet

```{r}
num_vars <- c("age", "height", "weight", "bmi", "sbp", "ldl", "time") #only continuous variable

preprocess_params <- preProcess(dat1[, num_vars], method = c("center", "scale"))
dat1[, num_vars] <- predict(preprocess_params, dat1[, num_vars])
dat2[, num_vars] <- predict(preprocess_params, dat2[, num_vars])
```

```{r}
# Preparing the data matrices for glmnet
x_train <- model.matrix(log_antibody ~ ., dat1)[, -1]  # Removing the intercept
y_train <- dat1$log_antibody

x_valid <- model.matrix(log_antibody ~ ., dat2)[, -1]
y_valid <- dat2$log_antibody
```

```{r}
set.seed(123)
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1) # LASSO with cross validation
best_lambda <- lasso_model$lambda.min
lasso_final <- glmnet(x_train, y_train, alpha = 1, lambda = best_lambda) # final model is based on optimal lambda
```

```{r}
# predicting with LASSO on validation data
best_lambda
lasso_pred <- predict(lasso_final, newx = x_valid)
lasso_rmse <- sqrt(mean((lasso_pred - y_valid)^2))
lasso_rmse
ss_total_lasso <- sum((y_valid - mean(y_valid))^2)
ss_res_lasso <- sum((lasso_pred - y_valid)^2)
r_squared_lasso <- 1 - ss_res_lasso / ss_total_lasso
n <- length(y_valid)
p <- length(coef(lasso_final)) - 1
lasso_adj_r2 <- 1 - ((1 - r_squared_lasso) * (n - 1) / (n - p - 1))
lasso_adj_r2
```
### using caret package for LASSO to compare the difference between the two methodologies (packages)
```{r}
## using caret for LASSO prediction
set.seed(123)
lasso_fit=train(y=y_train,
                  x=x_train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1, 
                                         lambda = exp(seq(1, -10, length = 1000))),  # range selected to perform well across a log-scale. Using fine-grid of 1000 values for precision
                  preProcess = c("center", "scale"),
                  trControl = ctrl1)

# selected tuning parameter and test error
lasso_caret_best_lambda = lasso_fit$bestTune$lambda
predy2_lasso_caret_fit = predict(lasso_fit, newdata = x_valid)
lasso_caret_rmse = sqrt(mean((y_valid - predy2_lasso_caret_fit)^2))

lasso_caret_best_lambda
lasso_caret_rmse

ss_total_lasso_caret <- sum((y_valid - mean(y_valid))^2)
ss_res_lasso_caret <- sum((predy2_lasso_caret_fit - y_valid)^2)
r_squared_lasso_caret <- 1 - ss_res_lasso_caret / ss_total_lasso_caret
n <- length(y_valid)
p <- length(coef(lasso_fit$finalModel, s = lasso_caret_best_lambda)) - 1
lasso_adj_r2_caret <- 1 - ((1 - r_squared_lasso_caret) * (n - 1) / (n - p - 1))

lasso_adj_r2_caret
```

The LASSO models built using both the glmnet and caret packages produced nearly identical results, with matching RMSE values (0.5684) and very similar adjusted R-squared values (0.0484 vs. 0.0482). This close agreement confirms that the modeling outcome is consistent across both approaches, and that the choice of package did not meaningfully affect the predictive performance.

## Training MARS model 

```{r}
mars_model <- earth(log_antibody ~ ., data = dat1)
summary(mars_model)
```

```{r}
# predicting with MARS on validation data
mars_pred <- predict(mars_model, newdata = dat2)
mars_rmse <- sqrt(mean((mars_pred - dat2$log_antibody)^2))

mars_rmse
```

* The MARS model achieves the lowest RMSE. Therefore MARS will be used as the preferred model for predicting log_antibody. Although further fine-tuning and additional feature exploration could further enhance the model's predictive power.

### MARS model tuning

```{r}
tune_grid <- expand.grid(degree = 1:3, nprune = seq(5, 50, by = 5))

mars_tune <- train(log_antibody ~ ., data = dat1, method = "earth", 
                   trControl = ctrl1, tuneGrid = tune_grid)

print(mars_tune$bestTune)
ggplot(mars_tune)
```

```{r}

# Train the MARS model with best tuning parameters
mars_model_tune <- train(log_antibody ~ ., 
                         data = dat1, 
                         method = "earth", 
                         trControl = ctrl1,
                         tuneGrid = data.frame(nprune = 10, degree = 1))

summary(mars_model_tune)
print(mars_model_tune$bestTune)

# Report the final model (regression function)
print(coef(mars_model_tune$finalModel))

mars_tune_pred <- predict(mars_model_tune, newdata = dat2)
mars_tune_rmse <- sqrt(mean((mars_tune_pred - dat2$log_antibody)^2))
mars_tune_rmse
```


```{r}
# variable importance plot for MARS
vip(mars_model_tune$finalModel, type = "nsubsets")
vip(mars_model_tune$finalModel, type = "rss")
```


```{r}
# Compute R-squared
ss_total_mars <- sum((dat2$log_antibody - mean(dat2$log_antibody))^2)
ss_res_mars <- sum((mars_tune_pred - dat2$log_antibody)^2)
r_squared_mars <- 1 - ss_res_mars / ss_total_mars

# Get n and number of selected terms (p)
n <- nrow(dat2)
p <- length(mars_model_tune$finalModel$selected.terms)

# Adjusted R-squared for MARS
mars_adj_r2 <- 1 - ((1 - r_squared_mars) * (n - 1) / (n - p - 1))


mars_adj_r2
mars_tune_rmse
```

```{r}
plot(mars_model)
plot(mars_model, which = 1)
```


\newpage

# Results

```{r}
res <- resamples(list(MLR = mlr_fit, 
                      LASSO = lasso_fit,
                      MARS = mars_model_tune))
summary(res)
# boxplot of RMSE performance for all models

bwplot(res, metric = "RMSE")
```
To ensure consistency across models, we trained the all three model using the caret package as well (model results using different methodologies were comparable) so it would be directly comparable to the others. This allowed us to evaluate all models under the same cross-validation framework and use the resamples() function for side-by-side performance comparison. By aligning the training method, we kept the evaluation fair and consistent across approaches.

```{r}
# Summary table
model_perf <- tibble(
  Model = c("Multiple Linear Regression (MLR)", 
            "LASSO Regression", 
            "MARS (Final, Tuned)"),
  RMSE = c(mlr_rmse, lasso_rmse, mars_tune_rmse),
  `Adjusted R-squared` = c(mlr_adj_r2, lasso_adj_r2, mars_adj_r2),
  Notes = c("Baseline model; assumes linear relationships",
            "Performs variable selection via L1 regularization",
            "Best performance; captures non-linear effects")
)

model_perf %>%
  gt() %>%
  tab_header(
    title = "Table: Model Performance on Independent Test Set (dat2)"
  ) %>%
  cols_label(
    Model = "Model",
    RMSE = "RMSE ↓",
    `Adjusted R-squared` = "Adjusted R-squared↑",
    Notes = "Notes"
  ) %>%
  fmt_number(columns = c(RMSE, `Adjusted R-squared`), decimals = 3) %>%
  tab_options(table.font.size = "small")
```

