---
title: "P8106 Midterm - Report"
author: "Kate Colvin (KAC2301), Jeong Yun (Lizy) Choi (JC6452), and Flora Pang (FP2513)"
mainfont: Arial
fontsize: 11pt
output: 
  pdf_document:
  latex_engine: xelatex
  extra_dependencies: ["float"]
header-includes: 
- \usepackage{titling}
- \setlength{\droptitle}{-1cm}
- \usepackage[small]{titlesec} 
urlcolor: blue
---

```{=latex}
\vspace{-1.5cm}
```

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = FALSE, # Hiding code in knitted pdf 
	warning = FALSE,
	fig.width = 7, 
  fig.height = 5,
  out.width = "90%", 
	fig.align = "center", 
	fig.pos = "H")

library(tidyverse)
library(gtsummary)
library(gt)
library(corrplot)
library(kableExtra)


library(caret)
library(glmnet) 
library(earth) 


```

# Introduction
In this project, our team explored the dataset collected from a study on evaluating antibody responses to a newly authorized vaccine. The primary outcome of interest is the log-transformed antibody level measured via dried blood spots. The dataset includes a range of demographic and clinical predictors such as age, gender, race/ethnicity, smoking status, BMI, chronic conditions, and time since vaccination.

Our goal is to develop a predictive model that characterizes how these factors influence antibody responses and asses how well this model generalizes to a new independent dataset collected at a later time point. By doing so, we hope to identify key predictors of antibody levels and evaluate the generalizability of our model across different dataset. 

# Exploratory Analysis 
Our full combined dataset includes 6,000 patients and contains demographic and health information, time since the patient received the vaccine, and log-transformed antibody level. There are two different subsets of data: data on 5,000 patients was initially collected for model training, and data on 1,000 additional patients was independently collected several months later for model testing and evaluation. 

Patients in both datasets have similar demographic and health characteristics (Table 1), but patients from the second collected dataset have a greater time since receiving the vaccine (an additional few months), and therefore slightly lower observed log-transformed antibody levels (Figures 1 and 2). Because we are more likely to observe lower antibody levels from patients in the testing dataset, it's possible that this difference may impact the prediction performance of our models, which are trained using the initial dataset. After plotting the most correlated quantitative variables versus log-transformed antibody level, we can see that the fitted line for the testing data is always flatter than the line of the training data, indicating a weaker relationship between these variables and the response (Figures 7-9). 

Across gender and smoking status, there were very slight differences in the observed antibody levels. Women had slightly greater antibody responses than men overall (Figure 3 and Table 2), while current smokers had slightly lower antibody responses than former and never-smokers (Figure 5 and Table 4). There were no observed differences in antibody responses across race (Figure 4 and Table 3). The quantitative variables that were most correlated with log-transformed antibody level were BMI, weight, and age. It's important to note that several predictors are also correlated with each other, such as BMI and weight, BMI and height, and SBP and age (Figure 6), which will impact variable selection. 

# Model Training
In this analysis, we trained three different models: Multiple Linear Regression (MLR), LASSO Regression, and Multivariate Adaptive Regression Splines (MARS). The following sections provides each step in the model training process, from pre-processing to final model selection.

## Data Pre-processing
* We ensured that there were no missing values in the training data, missing data were imputed or removed.

* Continuous variables were untouched, while categorical variables were converted to factor types (such as race, gender, smoking). 

* The response variable, log antibody, was log-transformed to normalize its distribution and reduce skewness.

## Multiple Linear Regression (MLR) Model 
We started by fitting a MLR model with all available predictors in the dataset and the model was fit using ordinary least squares regression (OLS).

The model was trained using the lm() function and the training process involved fitting the model to the data, estimating the regression coefficients for each predictor, and computing the residuals. The code below was used:


\begin{verbatim}
mlr_model <- lm(log_antibody ~ ., data = dat1)
\end{verbatim}

The coefficients were estimated through OLS regression, and the residuals were checked for normality. The model was trained on the entire training dataset, and no regularization was applied.(Table 5)

## LASSO Model 
To address potential multi-collinearity and perform feature selection, we used LASSO Regression, applying L1 regularization to shrink the coefficients of less important features to zero. The LASSO model was trained using the glmnet package. 

Since  LASSO is sensitive to differences in scale among predictor variables, numerical predictors were standardized before training to ensure fair comparison across variables. The preProcess() function from the caret package was used. The same transformations were applied to the validation and test datasets to maintain consistency.

The training procedure involved:

1. Creating a matrix of predictor variables (x) and a vector of the response variable (y)

2. Using cross-validation to select the best lambda (regularization parameter) based on the model’s performance. The model with the lowest cross-validation error was used for evaluation.

\begin{verbatim}
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1)
best_lambda <- lasso_model$lambda.min
lasso_final <- glmnet(x_train, y_train, alpha = 1, lambda = best_lambda)
\end{verbatim}


## Multivariate Adaptive Regression Splines (MARS) Model 
Non-linear regression MARS model automatically selects the best interactions and non-linear transformations of predictors. We first trained the MARS model without tuning, the used cross-validation to finetune it and determine the optimal number of terms and the degree of interactions (Table 6). 

\begin{verbatim}
mars_model <- earth(log_antibody ~ ., data = dat1)
mars_tune <- train(log_antibody ~ ., data = dat1, method = "earth", 
                   trControl = train_control, tuneGrid = tune_grid)
mars_model_tune <- train(log_antibody ~ ., 
                         data = dat1, 
                         method = "earth", 
                         trControl = train_control, 
                         tuneGrid = data.frame(nprune = 10, degree = 1))
\end{verbatim}

The best parameters were selected as follows:

* nprune = 10: The final model had 10 terms (lowest Generalized Cross Validation score)

* degree = 1: The degree of interaction was set to 1, which considers only pairwise interactions between features.

# Results 
To evaluate predictors of log antibody response, we trained three models using the original dataset (dat1): Multiple Linear Regression (MLR), LASSO Regression, and Multivariate Adaptive Regression Splines (MARS). Each model was then tested on an independent dataset (dat2) to assess generalizability. Model performance was evaluated using Root Mean Squared Error (RMSE), which captures prediction accuracy, and Adjusted R-squared (Adj. R²), which measures the proportion of variability explained while accounting for model complexity.

Among the three models, MARS model (Table 6) showed the best overall performance, with the lowest RMSE (0.533) and the highest adjusted R² (0.169). Both MLR and LASSO had identical RMSE values (0.568), but MLR explained more variance (Adj. R² = 0.149) than LASSO (Adj. R² = 0.048), suggesting that LASSO may have underfit slightly by shrinking less informative predictors. These results are summarized in Table 7.

MARS was particularly well-suited for this dataset because of its ability to flexibly model non-linear relationships and interactions, which are common in immune response data. Variables like age, BMI, and time since vaccination are unlikely to relate to antibody levels in a strictly linear way (Figure 6). While linear models assume constant change across the predictor range, MARS allows for thresholds and curve shapes that better reflect biological processes. This likely contributed to its stronger performance on the test set.

We also assessed model stability using 10-fold cross-validation through the caret package and compared RMSE distributions across models (Figure 10). MARS had the lowest median RMSE, reinforcing its predictive strength, though its variability across folds was slightly wider than MLR. This reflects a common trade-off: MARS offers more flexibility but may be slightly more variable; linear models are simpler and more stable, but risk missing important patterns.

In summary, MARS was selected as the final model due to its ability to handle complex, non-linear patterns in the data and its strong performance on an independent dataset. While it exhibited slightly more variability in resampling, it offered the best balance of accuracy and flexibility. These findings highlight the importance of model selection based on data structure and analysis goals — and support the use of flexible modeling strategies in understanding antibody responses to vaccination. 
\newpage


```{r}

load("dat1.RData") 
load("dat2.RData")

dat1 <- dat1 %>% janitor::clean_names()
dat2 <- dat2 %>%janitor::clean_names()

```

```{r}

# Combining data for summary table, data cleaning
dat1_com <- dat1 %>% mutate(set = "Training Data")
dat2_com <- dat2 %>% mutate(set = "Testing Data")

dat <- dat1_com %>% 
  rbind(dat2_com) %>% 
  rename(days_vaccinated = time) %>% 
  mutate(race = as.character(race), smoking = as.character(smoking)) %>% 
  mutate(race = case_match(
        race, "1" ~ "White", "2" ~ "Asian", "3" ~ "Black", "4" ~ "Hispanic"),
         gender = case_match(gender, 1 ~ "Male", 0 ~ "Female"), 
         smoking = case_match(
           smoking, "0" ~ "Never", "1" ~ "Former", "2" ~ "Current"))

# Summary table
dat %>% select(!id) %>% 
  tbl_summary(
    by = set, 
    label = list(age = "Age", gender = "Gender", race = "Race", smoking = "Smoking", 
                 height = "Height (cm)", weight = "Weight (kg)", bmi = "BMI", 
                 diabetes = "Diabetes", hypertension = "Hypertension", 
                 sbp = "Systolic Blood Pressure (mmHg)", ldl = "LDL Cholesterol (mg/dL)", 
                 days_vaccinated = "Time Since Vaccinated (days)", 
                 log_antibody = "Log-Transformed Antibody Level")) %>% 
  add_overall() %>% add_p() %>% 
  modify_caption("Summary of Patient Testing and Training Data (N=6000)") %>% 
  as_gt() %>% tab_options(table.font.size = 10)

```

```{r, out.width = "95%", fig.align = "center"}

# Antibody level 
plot_sets <- dat %>%  
  ggplot(aes(x = log_antibody, 
             fill = set, 
             color = set)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Log-Transformed Antibody Level", 
       y = "Density", 
       title = "Figure 1: Distribution of Log-Transformed Antibody Level, by Data Set") +
  theme_minimal()

# Time since vaccination (days)
plot_days <- dat %>%  
  ggplot(aes(x = days_vaccinated, 
             fill = set, 
             color = set)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Time Since Vaccinated (days)", 
       y = "Density", 
       title = "Figure 2: Distribution of Days Since Vaccination, by Data Set") +
  theme_minimal()

plot_sets
plot_days

```

```{r, out.width = "95%", fig.align = "center"}
# Antibody level, by gender
plot_gender <- dat %>%  
  ggplot(aes(x = log_antibody, fill = gender, color = gender)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Log-Transformed Antibody Level", y = "Density", 
       title = "Figure 3: Distribution of Log-Transformed Antibody Level, by Gender") +
  theme_minimal()
plot_gender

# Antibody level, by race
plot_race <- dat %>%  
  ggplot(aes(x = log_antibody, fill = race, color = race)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Log-Transformed Antibody Level", 
       y = "Density", 
       title = "Figure 4: Distribution of Log-Transformed Antibody Level, by Race") +
  theme_minimal()
plot_race

# Antibody level, by smoking status 
plot_smoking <- dat %>%  
  ggplot(aes(x = log_antibody, fill = smoking, color = smoking)) +
  geom_density(alpha = 0.3, linewidth = 1) +
  labs(x = "Log-Transformed Antibody Level", 
       y = "Density", 
       title = "Figure 5: Distribution of Log-Transformed Antibody Level, by Smoking") +
  theme_minimal()
plot_smoking

```

```{r}

dat %>% select(gender, log_antibody) %>% 
  tbl_summary(by = gender) %>% add_p() %>% 
  modify_caption("Log-Transformed Antibody Level, by Gender") %>% 
  as_gt() %>% tab_options(table.font.size = 11)

dat %>% 
  select(race, log_antibody) %>% 
  tbl_summary(by = race) %>% 
    add_p() %>% 
  modify_caption("Log-Transformed Antibody Level, by Race") %>% 
  as_gt() %>% tab_options(table.font.size = 11)

dat %>% select(smoking, log_antibody) %>% 
  tbl_summary(by = smoking) %>% 
    add_p() %>% 
  modify_caption("Log-Transformed Antibody Level, by Smoking Status") %>% 
  as_gt() %>% tab_options(table.font.size = 11)

```

```{r, warning=FALSE}

cor_matrix <- dat %>% 
  select(age, height, weight, bmi, sbp, ldl, days_vaccinated, log_antibody) %>% 
  rename("Age" = age, 
         "Height" = height,
         "Weight" = weight,
         "BMI" = bmi,
         "SBP" = sbp, 
         "LDL" = ldl,
         "Days Vaccinated" = days_vaccinated, 
         "Log(Antibody)" = log_antibody) %>% 
  cor()

cor_plot <- corrplot(cor_matrix,  
                     main = "Figure 6: Correlation Matrix of Numerical Variables", 
                     mar=c(0,0,1,0), cex.main = 1,
                     method = "color", 
                     addCoef.col = "black", 
                     tl.col = "black", 
                     number.cex = 0.8, 
                     tl.srt = 45, 
                     order = 'original', 
                     diag = F)

```

```{r, message=FALSE, out.width="90%", fig.align = "center"}
# Antibody level vs. BMI
plot_bmi <- dat %>% ggplot(aes(x = bmi, y = log_antibody, fill = set, color = set)) +
  geom_point(alpha = 0.3, size = 2) +
  geom_smooth(method = "lm") +
  labs(y = "Log-Transformed Antibody Level", x = "BMI", 
       title = "Figure 7: Log-Transformed Antibody Level vs. BMI") +
  theme_minimal()

# Antibody level vs. Weight
plot_weight <- dat %>% 
  ggplot(aes(x = weight, y = log_antibody, fill = set, color = set)) +
  geom_point(alpha = 0.3, size = 2) +
  geom_smooth(method = "lm") +
  labs(y = "Log-Transformed Antibody Level", x = "Weight", 
       title = "Figure 8: Log-Transformed Antibody Level vs. Weight") +
  theme_minimal()

# Antibody level vs. Age
plot_age <- dat %>% ggplot(aes(x = age, y = log_antibody, fill = set, color = set)) +
  geom_point(alpha = 0.3, size = 2) + geom_smooth(method = "lm") +
  labs(y = "Log-Transformed Antibody Level", x = "Age", 
       title = "Figure 9: Log-Transformed Antibody Level vs. Age") +
  theme_minimal()

plot_bmi
plot_weight
plot_age

```

```{r}
library(knitr)
library(kableExtra)
mlr_model <- lm(log_antibody ~ ., data = dat1)

summary_table_mlr <- coef(summary(mlr_model))[, "Estimate", drop = FALSE] %>%
  as.data.frame() %>%
  rownames_to_column(var = "Term")

kable(summary_table_mlr, digits = 4, 
      caption = "Regression Coefficients for MLR Model") %>%
  kable_styling(latex_options = c("striped", "hold_position"), 
                font_size = 11)
```
```{r}
library(knitr)
library(kableExtra)

mars_model <- earth(log_antibody ~ ., data = dat1)
summary_table_mars <- coef(mars_model)

mars_coef_df <- data.frame(
  Term = names(summary_table_mars),
  Estimate = as.numeric(summary_table_mars)
)

kable(mars_coef_df, digits = 4, caption = "Regression Coefficients for MARS Model") %>%
  kable_styling(latex_options = c("striped", "hold_position"), 
                font_size = 11)
```

```{r, message=FALSE, out.width="90%", fig.align = "center"}
library(lattice)

# Manually recreating RMSE values using summaries of each model (in the code document)
rmse_data <- data.frame(
  Model = factor(rep(c("MLR", "LASSO", "MARS"), each = 5)),
  RMSE = c(
    # MLR
    0.5177740, 0.5501364, 0.5528559, 0.5583168, 0.5674625,
    # LASSO
    0.5362151, 0.5422491, 0.5529600, 0.5572990, 0.5834269,
    # MARS
    0.5150003, 0.5188694, 0.5258153, 0.5335379, 0.5444253
  )
)

# Plotting the bwplot
bwplot(Model ~ RMSE,
       data = rmse_data,
       main = "Figure 10: 10-Fold Cross-Validation RMSE Comparison",
       xlab = "RMSE",
       ylab = "Model",
       panel = function(...){
         panel.bwplot(...)
         panel.grid(h = 0, v = -1)
       })
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(kableExtra)

# Manually entering model performance values
model_perf <- data.frame(
  Model = c("Multiple Linear Regression (MLR)", 
            "LASSO Regression", 
            "MARS"),
  RMSE = c(0.568, 0.568, 0.533),
  Adjusted_R_squared = c(0.149, 0.048, 0.169),
  Notes = c("Baseline model; assumes linear relationships",
            "Performs variable selection via L1 regularization",
            "Best performance; captures non-linear effects")
)

model_perf %>%
  kbl(caption = "Model Performance on Independent Test Set (dat2)",
      col.names = c("Model", "RMSE", "Adjusted R-squared", "Notes"),  # <- clean names
      booktabs = TRUE,
      align = c("l", "c", "c", "l")) %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"),
                font_size = 10)
```
